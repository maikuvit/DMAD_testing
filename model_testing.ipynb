{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\miche\\Desktop\\THESIS\\testing\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from deepface import DeepFace\n",
    "from lib import Autoencoder, FacesDataset, NoiseScheduler,unet, Demorpher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = torchvision.models.vgg16(pretrained=False) # autoencoder shape\n",
    "encoder = encoder.features[:11]\n",
    "\n",
    "autoencoder = Autoencoder(encoder)\n",
    "autoencoder.load_state_dict(torch.load('ae_Casia_30.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion = unet(1)\n",
    "diffusion.load_state_dict(torch.load('diffusion_65.pth',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = NoiseScheduler(0.01,0.05,20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Demorpher(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (7): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (2): ConvTranspose2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ConvTranspose2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (7): ConvTranspose2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (5): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (8): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (10): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (latent_unet): unet(\n",
       "    (activation): LeakyReLU(negative_slope=0.01)\n",
       "    (time_proj): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (input_conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conditional_emb): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): downBlock(\n",
       "        (down_sample_conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): downBlock(\n",
       "        (down_sample_conv): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): downBlock(\n",
       "        (down_sample_conv): Identity()\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_blocks): ModuleList(\n",
       "      (0): middleBlock(\n",
       "        (initialResnet): resnetBlock(\n",
       "          (activation): LeakyReLU(negative_slope=0.01)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_embedding): Sequential(\n",
       "            (0): LeakyReLU(negative_slope=0.01)\n",
       "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (res_input_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): middleBlock(\n",
       "        (initialResnet): resnetBlock(\n",
       "          (activation): LeakyReLU(negative_slope=0.01)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_embedding): Sequential(\n",
       "            (0): LeakyReLU(negative_slope=0.01)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (res_input_conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_blocks): ModuleList(\n",
       "      (0): upBlock(\n",
       "        (up_sample_conv): Identity()\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): upBlock(\n",
       "        (up_sample_conv): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): upBlock(\n",
       "        (up_sample_conv): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (resnet): ModuleList(\n",
       "          (0): resnetBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_embedding): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.01)\n",
       "              (1): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (res_input_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (selfatt): ModuleList(\n",
       "          (0): selfAttentionBlock(\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (norm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "            (satt): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "            )\n",
       "            (inConv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_norm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "    (output_conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Demorpher(autoencoder.get_encoder(), autoencoder.get_decoder(), diffusion,scheduler)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1269 identities.\n"
     ]
    }
   ],
   "source": [
    "FacesDataset = FacesDataset(\"Dataset/Neutral_Brightness\", \"Dataset/Morphed_Val_Brightness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_a,im_id,im_b, paths = FacesDataset[0]\n",
    "im_a = im_a.unsqueeze(0).to(device)\n",
    "im_id = im_id.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_ID nan:  tensor(False)\n",
      " z_A nan:  tensor(False)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "noise nan:  tensor(True)\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], grad_fn=<DivBackward0>)\n",
      "torch.Size([1, 1, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "im_idout = model(im_a,im_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_idout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = DeepFace.verify( img1_path = im_b.detach().numpy(), img2_path = im_idout.detach().numpy(), threshold=0.5)\n",
    "out2 = DeepFace.verify( img1_path = im_a.detach().numpy(), img2_path = im_idout.detach().numpy(), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_a,im_id,im_b, paths in tqdm(FacesDataset):\n",
    "    im_idout = model(im_a,im_id)\n",
    "    out = DeepFace.verify( img1_path = im_b, img2_path = im_idout, threshold=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
